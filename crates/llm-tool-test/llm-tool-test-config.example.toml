# llm-tool-test Configuration Example
#
# Copy this file to `llm-tool-test-config.toml` in your working directory
# to customize model pricing for cost tracking.

[models]

# Claude Models
[models.claude-3-5-sonnet]
input_cost_per_1k_tokens = 3.0
output_cost_per_1k_tokens = 15.0

[models.claude-3-5-haiku]
input_cost_per_1k_tokens = 0.8
output_cost_per_1k_tokens = 4.0

[models.claude-3-opus]
input_cost_per_1k_tokens = 15.0
output_cost_per_1k_tokens = 75.0

[models.claude-3]
input_cost_per_1k_tokens = 3.0
output_cost_per_1k_tokens = 15.0

[models.claude]
input_cost_per_1k_tokens = 3.0
output_cost_per_1k_tokens = 15.0

# OpenAI Models
[models.gpt-4o]
input_cost_per_1k_tokens = 2.5
output_cost_per_1k_tokens = 10.0

[models.gpt-4-turbo]
input_cost_per_1k_tokens = 10.0
output_cost_per_1k_tokens = 30.0

[models.gpt-4]
input_cost_per_1k_tokens = 30.0
output_cost_per_1k_tokens = 60.0

[models.gpt-3.5-turbo]
input_cost_per_1k_tokens = 0.5
output_cost_per_1k_tokens = 1.5

[models.gpt-3.5]
input_cost_per_1k_tokens = 0.5
output_cost_per_1k_tokens = 1.5

# Amp Models (De-prioritized)
# [models.smart]
# input_cost_per_1k_tokens = 3.0
# output_cost_per_1k_tokens = 15.0
# 
# [models.rush]
# input_cost_per_1k_tokens = 0.8
# output_cost_per_1k_tokens = 4.0
# 
# [models.free]
# input_cost_per_1k_tokens = 0.0
# output_cost_per_1k_tokens = 0.0
